AOiW - reconstruction of 3d models from sequence of images
==============================

The goal of the project was to tackle the problem of reconstructing 3d models from sequence 
 of images of given object. We implemented two solutions: one using classical method - `Structure
 From Motion` and the other using deep neural network - `Pix2Vox`.

## How to prepare `data` folder for experiments

For experiments to start, you need to make sure your `data` includes all the necessary data.
@TODO

```
├── data
│   ├── external       <- Data from third party sources.
│   ├── interim        <- Intermediate data that has been transformed.
│   ├── processed      <- The final, canonical data sets for modeling.
│   └── raw            <- The original, immutable data dump.

```


## How to run experiments for `Structure From Motion`

## How to run experiments for `Pix2Vox`

Make sure you have 4 pretrained models of `Pix2Vox` in `models` directory. In this
directory there is a `.txt` with links to those models. Here we are also posting these links:
1. https://gateway.infinitescript.com/?fileName=Pix2Vox-A-ShapeNet.pth - Pix2Vox-A
1. https://gateway.infinitescript.com/?fileName=Pix2Vox-F-ShapeNet.pth - Pix2Vox-F
1. https://gateway.infinitescript.com/?fileName=Pix2Vox%2B%2B-A-ShapeNet.pth - Pix2Vox++ A
1. https://gateway.infinitescript.com/?fileName=Pix2Vox%2B%2B-F-ShapeNet.pth - Pix2Vox++ F

To run training for the new models, run `train_pix2vox_models_and_test.sh` shell script.
This script trains new models and also tests them.

To use the trained models and run only tests, run `test_pix2vox_models.sh` shell script.

To visualize results generated by testing script, run `visualize_pix2vox_results.sh` shell script.
